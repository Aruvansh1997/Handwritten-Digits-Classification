{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c5514f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (pywrap_tensorflow_internal.py, line 114)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3441\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/var/folders/9f/94f26vqx4_j4g8wgjxtlbd580000gn/T/ipykernel_31959/3210280394.py\"\u001b[0m, line \u001b[1;32m5\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import tensorflow as tf\n",
      "  File \u001b[1;32m\"/opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages/tensorflow/__init__.py\"\u001b[0m, line \u001b[1;32m24\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \u001b[1;32m\"/opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages/tensorflow/python/__init__.py\"\u001b[0m, line \u001b[1;32m49\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from tensorflow.python import pywrap_tensorflow\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\"\u001b[0;36m, line \u001b[0;32m58\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from tensorflow.python.pywrap_tensorflow_internal import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\"\u001b[0;36m, line \u001b[0;32m114\u001b[0m\n\u001b[0;31m    def TFE_ContextOptionsSetAsync(arg1, async):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Comparing single layer MLP with deep MLP (using TensorFlow)\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Create model\n",
    "# Add more hidden layers to create deeper networks\n",
    "# Remember to connect the final hidden layer to the out_layer\n",
    "def create_multilayer_perceptron():\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 256  # 1st layer number of features\n",
    "    n_hidden_2 = 256  # 2nd layer number of features\n",
    "    n_input = 2376  # data input\n",
    "    n_classes = 2\n",
    "\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float\", [None, n_input])\n",
    "    y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer,x,y\n",
    "\n",
    "# Do not change this\n",
    "def preprocess():\n",
    "    pickle_obj = pickle.load(file=open('face_all.pickle', 'rb'))\n",
    "    features = pickle_obj['Features']\n",
    "    labels = pickle_obj['Labels']\n",
    "    train_x = features[0:21100] / 255\n",
    "    valid_x = features[21100:23765] / 255\n",
    "    test_x = features[23765:] / 255\n",
    "\n",
    "    labels = labels.T\n",
    "    train_y = np.zeros(shape=(21100, 2))\n",
    "    train_l = labels[0:21100]\n",
    "    valid_y = np.zeros(shape=(2665, 2))\n",
    "    valid_l = labels[21100:23765]\n",
    "    test_y = np.zeros(shape=(2642, 2))\n",
    "    test_l = labels[23765:]\n",
    "    for i in range(train_y.shape[0]):\n",
    "        train_y[i, train_l[i]] = 1\n",
    "    for i in range(valid_y.shape[0]):\n",
    "        valid_y[i, valid_l[i]] = 1\n",
    "    for i in range(test_y.shape[0]):\n",
    "        test_y[i, test_l[i]] = 1\n",
    "\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "# Construct model\n",
    "pred,x,y = create_multilayer_perceptron()\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load data\n",
    "train_features, train_labels, valid_features, valid_labels, test_features, test_labels = preprocess()\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(train_features.shape[0] / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = train_features[i * batch_size: (i + 1) * batch_size], train_labels[i * batch_size: (i + 1) * batch_size]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "    print(\"Optimization Finished!\")\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: test_features, y: test_labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e154742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.8.0\n",
      "  Downloading https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.8.0-py3-none-any.whl (46.5 MB)\n",
      "     |████████████████████████████████| 46.5 MB 362 kB/s            \n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.41.1.tar.gz (21.2 MB)\n",
      "     |████████████████████████████████| 21.2 MB 3.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gast>=0.2.0\n",
      "  Downloading gast-0.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting absl-py>=0.1.6\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 27.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages (from tensorflow==1.8.0) (1.21.2)\n",
      "Collecting tensorboard<1.9.0,>=1.8.0\n",
      "  Downloading tensorboard-1.8.0-py3-none-any.whl (3.1 MB)\n",
      "     |████████████████████████████████| 3.1 MB 86.7 MB/s            \n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/homebrew/Cellar/jupyterlab/3.1.10/libexec/lib/python3.9/site-packages (from tensorflow==1.8.0) (1.16.0)\n",
      "Collecting protobuf>=3.4.0\n",
      "  Downloading protobuf-3.19.1-py2.py3-none-any.whl (162 kB)\n",
      "     |████████████████████████████████| 162 kB 28.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/homebrew/lib/python3.9/site-packages (from tensorflow==1.8.0) (0.37.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 21.5 MB/s            \n",
      "\u001b[?25hCollecting html5lib==0.9999999\n",
      "  Downloading html5lib-0.9999999.tar.gz (889 kB)\n",
      "     |████████████████████████████████| 889 kB 93.8 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting werkzeug>=0.11.10\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "     |████████████████████████████████| 288 kB 37.4 MB/s            \n",
      "\u001b[?25hCollecting bleach==1.5.0\n",
      "  Downloading bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: grpcio, html5lib, termcolor\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.41.1-cp39-cp39-macosx_11_0_arm64.whl size=3319602 sha256=2052e49beee98a8b0d51eee2b79d70d0e8757e866df277ccce729328fdb9cd34\n",
      "  Stored in directory: /Users/aruvanshnigam/Library/Caches/pip/wheels/5b/59/3c/c17c0f6f502752a372ebfae25dad1a251f15e50f3aa849f0ee\n",
      "  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html5lib: filename=html5lib-0.9999999-py3-none-any.whl size=107233 sha256=745c2ac5fecb4330ab210fed83e9b789b2b007cb5bd895f77314efe592e21314\n",
      "  Stored in directory: /Users/aruvanshnigam/Library/Caches/pip/wheels/f5/09/3f/ff7233827f32dd8856574fd464fdc480892ecc575c6ce62145\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=52529dd3ac4644181e6dad549689d9fe14712f4489c220151241a9fc6c122faa\n",
      "  Stored in directory: /Users/aruvanshnigam/Library/Caches/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built grpcio html5lib termcolor\n",
      "Installing collected packages: html5lib, werkzeug, protobuf, markdown, bleach, termcolor, tensorboard, grpcio, gast, astor, absl-py, tensorflow\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 4.1.0\n",
      "    Uninstalling bleach-4.1.0:\n",
      "      Successfully uninstalled bleach-4.1.0\n",
      "Successfully installed absl-py-0.15.0 astor-0.8.1 bleach-1.5.0 gast-0.5.2 grpcio-1.41.1 html5lib-0.9999999 markdown-3.3.4 protobuf-3.19.1 tensorboard-1.8.0 tensorflow-1.8.0 termcolor-1.1.0 werkzeug-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.8.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f8dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
